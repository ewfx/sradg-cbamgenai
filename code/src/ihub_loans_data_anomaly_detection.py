# -*- coding: utf-8 -*-
"""ihub loans data Anomaly Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/ramupothuraju/ihub-loans-data-anomaly-detection.e9584e0b-5162-4e2e-b001-44a29094fc52.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250326/auto/storage/goog4_request%26X-Goog-Date%3D20250326T055729Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D489e30190c33bfa99632471f470ca97bf1a0c080570727edeaef065354b1afac0cca266e18610bfafb7fd7135c35faaf7f5529ffc599be9c129a631e2c822bd379cb7a10ae9a482050896482add1ec83a99fd6b2979c24f4ba4f66ad26f9d1546e4d5031a90a9b9ebef7ba5083c4f9ed323e6334a3968b1615094938d6e44756a09a590a64d2711d289c9e6b09a416d808c96ab6e75d33c2deb94a936282e85a5741e2ee5f109d8621cde2544bbef4d7e4b4f12a7f6b7f3d64132b9462af7b77d8e069d018ce5dc5209ef3686913c69b8d6e1e305ac8d61d085d6fdb4a693dd1987c91c346cabae57dc15583ad7fb7aaf3845ac15509b71ac33b529a0f719496
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
ramupothuraju_ihubloans1_path = kagglehub.dataset_download('ramupothuraju/ihubloans1')

print('Data source import complete.')

# Introduction

#**In this notebook, will analyze and build models to detect loans accounts ihub, GL balance transactions in a given dataset i hub Reconcililiation based on catalyst reconcilliation **

#We will explore the data, preprocess it, and apply several machine learning models to predict fraud, including Logistic Regression, Isolation Forest, and Local Outlier Factor.

#The performance of these models will be evaluated using common classification metrics.

"""# Step 1: Importing Libraries

We begin by importing the necessary libraries for data analysis, visualization, and model building:
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor

"""# Step 2: Loading and Exploring the iHub Loans Data

Next, we'll load the dataset and conduct some initial exploration:
"""

df = pd.read_csv('/content/sample_data/iHubLoans.csv')
df.head()
df.info()
df.describe()
df.isnull().sum()  # Checking for missing values

"""# Step 3: Account and ihub balnace and AU Distribution

We visualize the Account distribution to understand the balance between loans and non-balnaced loans transactions:
"""

# Class distribution
class_counts = df['Account'].value_counts()
print(class_counts)

# Visualize class distribution
plt.figure(figsize=(8, 6))
sns.countplot(x='Account', data=df)
plt.title('Account Distribution')
plt.show()

"""# Step 4: Feature-Target Separation and Data Splitting

We separate the features (X) from the target (y) and split the data into training and testing sets:
"""

X = df.drop(['Account', 'As_of_date','Currency','Primary Account','Secondary Account','Match Status','Comments','Anomaly'], axis=1)
y = df['Account']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Step 5: Scaling the Features

To improve model performance, we scale the features using StandardScaler:
"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Step 6: Training a Logistic Regression Model

We build and train a Logistic Regression model:
"""

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# Predict on the test set
y_pred_lr = lr_model.predict(X_test)

"""# Step 7: Outlier Detection with Isolation Forest and Local Outlier Factor

We implement two unsupervised anomaly detection algorithms—Isolation Forest and Local Outlier Factor (LOF)—to detect balance difference:
"""

# Isolation Forest
isolation_forest = IsolationForest(contamination=0.01, random_state=42)
y_pred_if = isolation_forest.fit_predict(X)

# Local Outlier Factor
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)
y_pred_lof = lof.fit_predict(X)

# Convert -1 to 1 (fraud) and 1 to 0 (normal)
y_pred_if = np.where(y_pred_if == -1, 1, 0)
y_pred_lof = np.where(y_pred_lof == -1, 1, 0)

# Evaluate both models
print("Isolation Forest:")
print(confusion_matrix(y, y_pred_if))

"""# Step 8: Reconciliation Analysis

We'll calculate the correlation between features and visualize it using a heatmap for reconciliation:
"""

df2 = df.drop(['Account', 'As_of_date','Currency','Primary Account','Secondary Account','Match Status','Comments','Anomaly'], axis=1)
correlation_matrix = df2.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False, linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""# Step 9: Visualizing Feature Distributions by Class

We visualize the distribution of the  GL and ihub balance based on account:
"""

features = ['GL Balance', 'ihub balnce', 'Balance Difference', 'Account', 'Company']
plt.figure(figsize=(15, 10))

for i, feature in enumerate(features):
    plt.subplot(2, 3, i+1)
    sns.boxplot(x='Account', y=feature, data=df)
    plt.title(f'{feature} vs Account')

plt.tight_layout()
plt.show()

"""# Step 10: Separate and Describe reconcilliatio between ihub and GL balance based on hitorical Transactions

We separate Separate and Describe reconcilliatio between ihub and GL balance based on hitorical Transactions and display descriptive statistics for both:
"""

fraud = df2[df2['Balance Difference'] < 0]
non_fraud = df2[df['Balance Difference'] >= 0]

print("Math Loan ihub balance Transactions:")
print(fraud.describe())

print("\nNon-match loan ihub balance Transactions:")
print(non_fraud.describe())

"""# Step 11: Comparing Model Performance

Finally, we compare the performance of all models in terms of accuracy, precision, recall, and F1-score:
"""

results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Isolation Forest', 'Local Outlier Factor'],
    'Accuracy': [accuracy_score(y_test, y_pred_lr), accuracy_score(y, y_pred_if), accuracy_score(y, y_pred_lof)],
    })

print(results)

"""# Step 12: Visualizing iHub Amount Distribution by loan Account
We visualize the distribution of the transaction amounts for loan accounts:
"""

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='Balance Difference', hue='Account', bins=50, kde=True)
plt.title('ihub balnce Distribution by Account')
plt.xlim(0, 2000)
plt.show()

"""# Conclusion
Smarter reconcilliation and anomally detection using pandas , linear regression Outlier Detection with Isolation Forest and Local Outlier Factor
"""